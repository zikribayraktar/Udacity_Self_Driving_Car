{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Detection Project -- Classification Part\n",
    "\n",
    "Zikri Bayraktar, Ph.D.\n",
    "\n",
    "This project has two parts ( in this notebook, we will focus on Part 1 ):\n",
    "1. Train a classifier to identify cars on an image of a road.\n",
    "2. Create a pipeline to detect vehicles in a video stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Train a classifier to identify cars vs. non-cars (i.e. background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in all available car images for training classifier:\n",
    "\n",
    "vehicle_list=[]\n",
    "for foldername in os.listdir('folder_vehicles'):\n",
    "    for filename in glob.glob('folder_vehicles/'+str(foldername)+'/*.png'):\n",
    "        vehicle_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in all available nonCar images for training classifier:\n",
    "\n",
    "non_vehicle_list=[]\n",
    "for filename in glob.glob('folder_non_vehicles/*.png'):\n",
    "    non_vehicle_list.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some useful functions from lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute binned color features.\n",
    "# This function simply resizes image to a smaller size and creates a 1D feature vector to return.\n",
    "# By shrinking the image, we are reducing the dimensions while still maintaining some relavant \n",
    "# features to help us identify cars visually.\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    #print('bin_spatial ' + str(max(features)))   --> range of [0,1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the RGB channels separately\n",
    "    c1hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    c2hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    c3hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Generating bin centers\n",
    "    bin_edges = c1hist[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((c1hist[0], c2hist[0], c3hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    #return c1hist, c2hist, c3hist, bin_centers, hist_features\n",
    "    #print('hist ' + str(hist_features))\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_color_features(imgs, cspace='RGB', spatial_size=(32, 32), hist_bins=32, hist_range=(0, 256)):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        \n",
    "        image = image*255  \n",
    "        \n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        else: feature_image = np.copy(image)      \n",
    "        \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #print('spatial ' + str(max(spatial_features)))\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        #print('hist ' + str(max(hist_features)))\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract HOG features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_hog_features(imgs, cspace='RGB', orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        image=image*255\n",
    "        \n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(hog_features)\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    draw_img = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(draw_img, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to search for template matches\n",
    "# and return a list of bounding boxes\n",
    "def find_matches(img, template_list):\n",
    "    # Define an empty list to take bbox coords\n",
    "    bbox_list = []\n",
    "    # Define matching method\n",
    "    # Other options include: cv2.TM_CCORR_NORMED', 'cv2.TM_CCOEFF', 'cv2.TM_CCORR',\n",
    "    #         'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED'\n",
    "    method = cv2.TM_CCOEFF_NORMED\n",
    "    # Iterate through template list\n",
    "    for temp in template_list:\n",
    "        # Read in templates one by one\n",
    "        tmp = mpimg.imread(temp)\n",
    "        # Use cv2.matchTemplate() to search the image\n",
    "        result = cv2.matchTemplate(img, tmp, method)\n",
    "        # Use cv2.minMaxLoc() to extract the location of the best match\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        # Determine a bounding box for the match\n",
    "        w, h = (tmp.shape[1], tmp.shape[0])\n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        # Append bbox position to list\n",
    "        bbox_list.append((top_left, bottom_right))\n",
    "        # Return the list of bounding boxes\n",
    "        \n",
    "    return bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "## Function to plot 3D figures to visualize color spaces:\n",
    "def plot3d(pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=((0, 255), (0, 255), (0, 255))):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extract COLOR features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Color Features:\n",
    "spatial = 16\n",
    "histbin = 32\n",
    "colorspace = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "\n",
    "\n",
    "car_color_features = extract_color_features(vehicle_list, cspace=colorspace, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=histbin, hist_range=(0, 1.0))\n",
    "\n",
    "\n",
    "notcar_color_features = extract_color_features(non_vehicle_list, cspace=colorspace, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=histbin, hist_range=(0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract HOG Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orient = 9\n",
    "pix_per_cell = 16\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\"  # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "t=time.time()\n",
    "car_hog_features = extract_hog_features(vehicle_list, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "notcar_hog_features = extract_hog_features(non_vehicle_list, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "8792\n",
      "5068\n",
      "5068\n"
     ]
    }
   ],
   "source": [
    "print(len(car_color_features))\n",
    "print(len(car_hog_features))\n",
    "print(len(notcar_color_features))\n",
    "print(len(notcar_hog_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning! Pay Attention!\n",
    "# Note that car_all_features is a 'list'. Each element of this list represents the combined\n",
    "# features of a single image. \n",
    "\n",
    "# Combine color and hog features for images labeled as CAR\n",
    "car_all_features=[]\n",
    "for colorf,hogf in zip(car_color_features,car_hog_features):\n",
    "    car_all_features.append(np.concatenate((colorf, hogf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine color and hog features for images labeled as NONCAR\n",
    "notcar_all_features=[]\n",
    "for colorf, hogf in zip(notcar_color_features, notcar_hog_features):\n",
    "    notcar_all_features.append(np.concatenate((colorf,hogf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(notcar_all_features[0])\n",
    "#print(car_all_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627.0\n"
     ]
    }
   ],
   "source": [
    "print(max(car_color_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack the CAR and NONCAR\n",
    "X = np.vstack((car_all_features, notcar_all_features)).astype(np.float64)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack the corresponding labels:\n",
    "y = np.hstack((np.ones(len(car_all_features)), np.zeros(len(notcar_all_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a per-column scaler only on the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X_train and X_test\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.87950479,  2.00008755, -0.57689187, ..., -0.07921256,\n",
       "       -0.09748271, -0.17911283])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using spatial binning of: 16 and 32 histogram bins\n",
      "Feature vector length: 1836\n",
      "4.03 Seconds to train SVC...\n",
      "Train Accuracy of SVC =  1.0\n",
      "Test Accuracy of SVC =  0.9931\n"
     ]
    }
   ],
   "source": [
    "print('Using spatial binning of:',spatial, 'and', histbin,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Train Accuracy of SVC = ', round(svc.score(X_train, y_train), 4))\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My SVC predicts:  [ 0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.\n",
      "  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.\n",
      "  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  0.  0.\n",
      "  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  1.  0.  1.\n",
      "  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.]\n",
      "For theselabels:  [ 0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.\n",
      "  1.  1.  0.  1.  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.  0.  1.  1.\n",
      "  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  0.  0.\n",
      "  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  1.  0.  1.\n",
      "  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.]\n",
      "0.01651 Seconds to predict 100 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "n_predict = 100\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these' 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model to a file\n",
    "import pickle\n",
    "\n",
    "# Save the model:\n",
    "with open('model_HSV_hist_range.pickle', 'wb') as handle:\n",
    "    pickle.dump(svc, handle)\n",
    "    \n",
    "# Save the scalar function used to normalize the data:\n",
    "with open('scalar_HSV_hist_range.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_scaler, handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a model from a pickle file:\n",
    "with open('model_YCrCb.pickle', 'rb') as handle:\n",
    "    inmodel = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of loaded model =  0.9957\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy of loaded model = ', round(inmodel.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some References:\n",
    "# 1. Pickle file write/read:\n",
    "# https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "# 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
